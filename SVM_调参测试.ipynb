{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 处理 20180127\n",
    "\n",
    "#### 总结 20180209\n",
    "* 适用：小样本、分类问题\n",
    "* 优点：\n",
    "* 缺点：\n",
    "* 重要参数：\n",
    "\n",
    "#### 完成：\n",
    "* 得分0.80382\n",
    "* 默认核函数下，参数C、Gamma调式，但Gamma规律不明确\n",
    "* 大致过程，具体求解还需要\n",
    "\n",
    "#### 暂确定还需要：\n",
    "* Gamma 及其它参数调式\n",
    "* 核函数选择\n",
    "* 如何避免局部最优情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.413493</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.486592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age         Fare        Parch  PassengerId       Pclass  \\\n",
       "count  1046.000000  1308.000000  1309.000000  1309.000000  1309.000000   \n",
       "mean     29.881138    33.295479     0.385027   655.000000     2.294882   \n",
       "std      14.413493    51.758668     0.865560   378.020061     0.837836   \n",
       "min       0.170000     0.000000     0.000000     1.000000     1.000000   \n",
       "25%      21.000000     7.895800     0.000000   328.000000     2.000000   \n",
       "50%      28.000000    14.454200     0.000000   655.000000     3.000000   \n",
       "75%      39.000000    31.275000     0.000000   982.000000     3.000000   \n",
       "max      80.000000   512.329200     9.000000  1309.000000     3.000000   \n",
       "\n",
       "             SibSp    Survived  \n",
       "count  1309.000000  891.000000  \n",
       "mean      0.498854    0.383838  \n",
       "std       1.041658    0.486592  \n",
       "min       0.000000    0.000000  \n",
       "25%       0.000000    0.000000  \n",
       "50%       0.000000    0.000000  \n",
       "75%       1.000000    1.000000  \n",
       "max       8.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据预处理--同feature\n",
    "\n",
    "#导入必要的包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame,Series\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#读入文件\n",
    "data_train = pd.read_csv(\"c:/Users/chai/Downloads/train.csv\")\n",
    "data_test = pd.read_csv(\"c:/Users/chai/Downloads/test.csv\")\n",
    "\n",
    "# For Pre-Processing, combine train/test to simultaneously apply transformations\n",
    "Survived = data_train['Survived'].copy()\n",
    "train_df = data_train.drop('Survived', axis=1)\n",
    "\n",
    "traindex = train_df.index\n",
    "testdex = data_test.index\n",
    "\n",
    "\n",
    "data_all = pd.concat([data_train,data_test],ignore_index = True)\n",
    "data_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "c:\\users\\chai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n",
      "c:\\users\\chai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "c:\\users\\chai\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>TicketLen</th>\n",
       "      <th>...</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603970</td>\n",
       "      <td>-0.503595</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.434672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608524</td>\n",
       "      <td>0.734503</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>2</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>2.511806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436821</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.300847</td>\n",
       "      <td>-0.490544</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.539904</td>\n",
       "      <td>1</td>\n",
       "      <td>3.326516</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.381181</td>\n",
       "      <td>0.382925</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>4</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>1.775186</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.285603</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.381181</td>\n",
       "      <td>-0.488127</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.329441</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.285603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Parch  PassengerId     SibSp  Survived  FamilySize  \\\n",
       "0 -0.603970 -0.503595 -0.445            1  0.481288       0.0    0.073352   \n",
       "1  0.608524  0.734503 -0.445            2  0.481288       1.0    0.073352   \n",
       "2 -0.300847 -0.490544 -0.445            3 -0.479087       1.0   -0.558346   \n",
       "3  0.381181  0.382925 -0.445            4  0.481288       1.0    0.073352   \n",
       "4  0.381181 -0.488127 -0.445            5 -0.479087       0.0   -0.558346   \n",
       "\n",
       "   NameLength  IsAlone  TicketLen     ...       sex_female  sex_male  \\\n",
       "0   -0.434672        0   0.798033     ...                0         1   \n",
       "1    2.511806        0   0.436821     ...                1         0   \n",
       "2   -0.539904        1   3.326516     ...                1         0   \n",
       "3    1.775186        0  -0.285603     ...                1         0   \n",
       "4   -0.329441        1  -0.285603     ...                0         1   \n",
       "\n",
       "   pclass_1  pclass_2  pclass_3  title_Master  title_Miss  title_Mr  \\\n",
       "0         0         0         1             0           0         1   \n",
       "1         1         0         0             0           0         0   \n",
       "2         0         0         1             0           1         0   \n",
       "3         1         0         0             0           0         0   \n",
       "4         0         0         1             0           0         1   \n",
       "\n",
       "   title_Mrs  title_Other  \n",
       "0          0            0  \n",
       "1          1            0  \n",
       "2          0            0  \n",
       "3          1            0  \n",
       "4          0            0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#直接计算衍生变量\n",
    "data_all['FamilySize'] = data_all.SibSp + data_all.Parch +1\n",
    "data_all['NameLength'] = data_all.Name.apply(len)\n",
    "data_all['IsAlone'] = 0\n",
    "data_all['IsAlone'][data_all['FamilySize'] == 1] = 1   \n",
    "## 或 df.loc[df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "data_all['TicketLen'] = data_all.Ticket.apply(len)\n",
    "data_all.head()\n",
    "\n",
    "\n",
    "df = data_all\n",
    "\n",
    "df['Title']=0\n",
    "df['Title']=df.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n",
    "df['Title'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don','Dona'],\n",
    "                          ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "df.loc[(df.Age.isnull())&(df.Title=='Mr'),'Age']= 33\n",
    "df.loc[(df.Age.isnull())&(df.Title=='Mrs'),'Age']=36\n",
    "df.loc[(df.Age.isnull())&(df.Title=='Master'),'Age']=5\n",
    "df.loc[(df.Age.isnull())&(df.Title=='Miss'),'Age']=22\n",
    "df.loc[(df.Age.isnull())&(df.Title=='Rare'),'Age']=46\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.Embarked = df.Embarked.fillna(df.Embarked.mode().iloc[0])\n",
    "# Continuous Variable\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for col in ['Fare','Age','NameLength']:\n",
    "    transf = df[col].values.reshape(-1,1)\n",
    "    scaler = preprocessing.StandardScaler().fit(transf)\n",
    "    df[col] = scaler.transform(transf)\n",
    "\n",
    "#增加标准化：\n",
    "for col in ['NameLength','TicketLen','Parch','FamilySize','SibSp']:\n",
    "    transf = df[col].values.reshape(-1,1)\n",
    "    scaler = preprocessing.StandardScaler().fit(transf)\n",
    "    df[col] = scaler.transform(transf)\n",
    "\n",
    "    \n",
    "df['cabinfix']=1\n",
    "df['cabinfix'][df['Cabin'].isnull()] = 0\n",
    "df.head()\n",
    "\n",
    "\n",
    "#哑变量相关：Sex\\ Pclass \\ Embarked ,\n",
    "\n",
    "dum_Embarked = pd.get_dummies(data_all.Embarked,prefix = 'embarked')\n",
    "dum_Sex = pd.get_dummies(data_all.Sex,prefix = 'sex')\n",
    "dum_Pclass = pd.get_dummies(data_all.Pclass,prefix = 'pclass')\n",
    "dum_nametitle = pd.get_dummies(df['Title'],prefix = 'title')\n",
    "df = pd.concat([df,dum_Embarked,dum_Sex,dum_Pclass,dum_nametitle],axis=1)\n",
    "\n",
    "df = df.drop(['Name','Sex','Embarked','Title','Pclass','Ticket','Cabin'],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.describe().to_csv(\"D:/work/others/kaggle/数据描述统计0127用于svm优化.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 24 columns):\n",
      "Age             891 non-null float64\n",
      "Fare            891 non-null float64\n",
      "Parch           891 non-null float64\n",
      "PassengerId     891 non-null int64\n",
      "SibSp           891 non-null float64\n",
      "Survived        891 non-null float64\n",
      "FamilySize      891 non-null float64\n",
      "NameLength      891 non-null float64\n",
      "IsAlone         891 non-null int64\n",
      "TicketLen       891 non-null float64\n",
      "cabinfix        891 non-null int64\n",
      "embarked_C      891 non-null uint8\n",
      "embarked_Q      891 non-null uint8\n",
      "embarked_S      891 non-null uint8\n",
      "sex_female      891 non-null uint8\n",
      "sex_male        891 non-null uint8\n",
      "pclass_1        891 non-null uint8\n",
      "pclass_2        891 non-null uint8\n",
      "pclass_3        891 non-null uint8\n",
      "title_Master    891 non-null uint8\n",
      "title_Miss      891 non-null uint8\n",
      "title_Mr        891 non-null uint8\n",
      "title_Mrs       891 non-null uint8\n",
      "title_Other     891 non-null uint8\n",
      "dtypes: float64(8), int64(3), uint8(13)\n",
      "memory usage: 94.8 KB\n"
     ]
    }
   ],
   "source": [
    "#拆分成两个数据集：\n",
    "df_train_fix = df[df.Survived.notnull()]\n",
    "df_train_fix.describe()\n",
    "var_to_use = 'Age|Fare|Parch|SibSp|FamilySize|Namelength|TicketLen|cabinfix|embarked_.*|sex_.*|pclass_.*|title_.*'\n",
    "all_data = df_train_fix.filter(regex=var_to_use)\n",
    "X = all_data.as_matrix()[:,:]\n",
    "y = df_train_fix['Survived'].as_matrix()\n",
    "df_train_fix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83165, std: 0.02888, params: {'gamma': 0.01, 'C': 3.5},\n",
       "  mean: 0.83726, std: 0.03220, params: {'gamma': 0.029999999999999999, 'C': 3.5},\n",
       "  mean: 0.83502, std: 0.03576, params: {'gamma': 0.049999999999999996, 'C': 3.5},\n",
       "  mean: 0.82828, std: 0.04009, params: {'gamma': 0.069999999999999993, 'C': 3.5},\n",
       "  mean: 0.82379, std: 0.03862, params: {'gamma': 0.089999999999999983, 'C': 3.5},\n",
       "  mean: 0.82379, std: 0.04414, params: {'gamma': 0.10999999999999997, 'C': 3.5},\n",
       "  mean: 0.81930, std: 0.03843, params: {'gamma': 0.12999999999999998, 'C': 3.5},\n",
       "  mean: 0.81145, std: 0.03976, params: {'gamma': 0.14999999999999999, 'C': 3.5},\n",
       "  mean: 0.80920, std: 0.03743, params: {'gamma': 0.16999999999999998, 'C': 3.5},\n",
       "  mean: 0.80920, std: 0.03600, params: {'gamma': 0.18999999999999997, 'C': 3.5},\n",
       "  mean: 0.80584, std: 0.03597, params: {'gamma': 0.20999999999999996, 'C': 3.5},\n",
       "  mean: 0.80247, std: 0.03490, params: {'gamma': 0.22999999999999998, 'C': 3.5},\n",
       "  mean: 0.80247, std: 0.03553, params: {'gamma': 0.24999999999999997, 'C': 3.5},\n",
       "  mean: 0.80247, std: 0.03553, params: {'gamma': 0.26999999999999996, 'C': 3.5},\n",
       "  mean: 0.80359, std: 0.03693, params: {'gamma': 0.28999999999999998, 'C': 3.5},\n",
       "  mean: 0.80247, std: 0.03562, params: {'gamma': 0.30999999999999994, 'C': 3.5},\n",
       "  mean: 0.80247, std: 0.03517, params: {'gamma': 0.32999999999999996, 'C': 3.5},\n",
       "  mean: 0.80135, std: 0.03477, params: {'gamma': 0.34999999999999998, 'C': 3.5},\n",
       "  mean: 0.80584, std: 0.03067, params: {'gamma': 0.36999999999999994, 'C': 3.5},\n",
       "  mean: 0.80696, std: 0.03096, params: {'gamma': 0.38999999999999996, 'C': 3.5},\n",
       "  mean: 0.80696, std: 0.03244, params: {'gamma': 0.40999999999999992, 'C': 3.5},\n",
       "  mean: 0.80471, std: 0.03067, params: {'gamma': 0.42999999999999994, 'C': 3.5},\n",
       "  mean: 0.80359, std: 0.02950, params: {'gamma': 0.44999999999999996, 'C': 3.5},\n",
       "  mean: 0.80584, std: 0.02896, params: {'gamma': 0.46999999999999992, 'C': 3.5},\n",
       "  mean: 0.80696, std: 0.03126, params: {'gamma': 0.48999999999999994, 'C': 3.5},\n",
       "  mean: 0.83277, std: 0.03034, params: {'gamma': 0.01, 'C': 4},\n",
       "  mean: 0.83726, std: 0.03220, params: {'gamma': 0.029999999999999999, 'C': 4},\n",
       "  mean: 0.83389, std: 0.03492, params: {'gamma': 0.049999999999999996, 'C': 4},\n",
       "  mean: 0.82379, std: 0.03996, params: {'gamma': 0.069999999999999993, 'C': 4},\n",
       "  mean: 0.82492, std: 0.04161, params: {'gamma': 0.089999999999999983, 'C': 4},\n",
       "  mean: 0.82155, std: 0.04008, params: {'gamma': 0.10999999999999997, 'C': 4},\n",
       "  mean: 0.81481, std: 0.03726, params: {'gamma': 0.12999999999999998, 'C': 4},\n",
       "  mean: 0.81145, std: 0.03904, params: {'gamma': 0.14999999999999999, 'C': 4},\n",
       "  mean: 0.81033, std: 0.03550, params: {'gamma': 0.16999999999999998, 'C': 4},\n",
       "  mean: 0.80584, std: 0.03597, params: {'gamma': 0.18999999999999997, 'C': 4},\n",
       "  mean: 0.80471, std: 0.03497, params: {'gamma': 0.20999999999999996, 'C': 4},\n",
       "  mean: 0.80022, std: 0.03358, params: {'gamma': 0.22999999999999998, 'C': 4},\n",
       "  mean: 0.80247, std: 0.03517, params: {'gamma': 0.24999999999999997, 'C': 4},\n",
       "  mean: 0.80247, std: 0.03658, params: {'gamma': 0.26999999999999996, 'C': 4},\n",
       "  mean: 0.80247, std: 0.03490, params: {'gamma': 0.28999999999999998, 'C': 4},\n",
       "  mean: 0.80359, std: 0.03334, params: {'gamma': 0.30999999999999994, 'C': 4},\n",
       "  mean: 0.80471, std: 0.03292, params: {'gamma': 0.32999999999999996, 'C': 4},\n",
       "  mean: 0.80584, std: 0.03398, params: {'gamma': 0.34999999999999998, 'C': 4},\n",
       "  mean: 0.80584, std: 0.03255, params: {'gamma': 0.36999999999999994, 'C': 4},\n",
       "  mean: 0.80584, std: 0.03096, params: {'gamma': 0.38999999999999996, 'C': 4},\n",
       "  mean: 0.80359, std: 0.03029, params: {'gamma': 0.40999999999999992, 'C': 4},\n",
       "  mean: 0.80359, std: 0.02907, params: {'gamma': 0.42999999999999994, 'C': 4},\n",
       "  mean: 0.80584, std: 0.03096, params: {'gamma': 0.44999999999999996, 'C': 4},\n",
       "  mean: 0.81033, std: 0.03305, params: {'gamma': 0.46999999999999992, 'C': 4},\n",
       "  mean: 0.81257, std: 0.03395, params: {'gamma': 0.48999999999999994, 'C': 4}],\n",
       " {'C': 3.5, 'gamma': 0.029999999999999999},\n",
       " 0.8372615039281706)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#网格搜索\n",
    "# list(np.arange(0.1,3.2,0.2))\n",
    "# list(np.arange(0.01,0.5,0.02))\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_test1 ={'C':[3.5,4],'gamma':list(np.arange(0.01,0.5,0.02))}\n",
    "gsearch1= GridSearchCV(estimator = SVC(random_state = 1),\n",
    "                       param_grid =param_test1,scoring='accuracy',cv=10)  \n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行调式记录\n",
    "20180123 \n",
    "* 首次无优化+ 默认参数（random_state = 1）,交叉验证score 0.856933010481568：  0.79904\n",
    "* C=2.2，0.79425\n",
    "* c1.7,gamma 0.1   线上 0.78468\n",
    "\n",
    "20180127\n",
    "* {'C': 1.7, 'gamma': 0.1}, 0.8327721661054994)\n",
    "* 增加两个变量的标准化之后  {'C': 2.2, 'gamma': 'auto'}, 0.8361391694725028) —— 0.79425\n",
    "* 增加五个变量的标准化之后  {'C': 2.2, 'gamma': 'auto'}, 0.835016835016835) \n",
    "* 固定gamma找c  {'C': 1.9000000000000004, 'gamma': 'auto'}, 0.835016835016835)\n",
    "* {'C':[1.8,1.9,1.901,2],'gamma':['auto',0.001,0.002,0.003]} ==》 {'C': 1.8, 'gamma': 'auto'}, 0.835016835016835) ===》 C 与 gamma相互还是有影响 —— 0.79904\n",
    "* param_test1 ={'C':[1.9,2,3,4,5,10],'gamma':list(np.arange(0.01,0.5,0.02))}　＝》 {'C': 4, 'gamma': 0.0299999},0.8372615039281706)===》 C之前应是陷入局部最小了？ —— 0.80382\n",
    "* {'C':[1.9,2,3.5,4,4.5,5,8],'gamma':['auto',0.01,0.03,0.029,0.04,0.05,0.008]} => {'C': 3.5, 'gamma': 0.03}, 0.8372615039281706) => 0.80382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预测评价。\n",
    "df_test_fix = df[df.Survived.isnull()]\n",
    "test_data = df_test_fix.filter(regex= var_to_use)\n",
    "test_X = test_data.as_matrix()[:,:]\n",
    "predict_y = gsearch1.predict(test_X)\n",
    "result = pd.DataFrame({'PassengerId':df_test_fix['PassengerId'].as_matrix(), 'Survived':predict_y.astype(np.int32)})\n",
    "result.head(30)\n",
    "result.to_csv(\"D:/work/others/kaggle/20180127增加5个标准化girdserch_acc_C3.4gamma_0.03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 开始svm  baseline\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(random_state=1)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81111111  0.84444444  0.7752809   0.87640449  0.83146067  0.80898876\n",
      "  0.83146067  0.79775281  0.87640449  0.85227273]\n"
     ]
    }
   ],
   "source": [
    "print(cross_validation.cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.82101732,  0.35899728,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-2.11958692, -0.23628556,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.75553161, -0.48812669,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [-1.96802522, -0.42851043,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.13443586, -0.50407824,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.3008465 , -0.06371879,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([215, 210])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题列表\n",
    "* 映射到高维空间的核函数是怎么选择的？怎么保证映射后就是线性可分的？\n",
    "> 分为：线性可分、不可分等情形，对应取核函数。sklearn上默认是rbf。其它待查。\n",
    "* 超平面是怎么算出来的？\n",
    "* 有哪些参数需要调整，如何调整。\n",
    "> rbf核函数中C和gamma ：\n",
    ">SVM模型有两个非常重要的参数C与gamma。其中 C是惩罚系数，即对误差的宽容度。c越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差\n",
    "\n",
    "> gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。\n",
    "\n",
    "> C可能陷入局部最小，调式时候选值要有跳跃. Gamma，暂没发现规律,取值较小。\n",
    "\n",
    "* 交叉验证调参时，评价指标用acc　和　用roc 有区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参考资料\n",
    "\n",
    "* [sklearn中SVM调参说明及经验总结](https://xijunlee.github.io/2017/03/29/sklearn%E4%B8%ADSVM%E8%B0%83%E5%8F%82%E8%AF%B4%E6%98%8E%E5%8F%8A%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/)\n",
    "* 统计学习方法 李航\n",
    "* [sigma-gamma](http://haohanw.blogspot.com/2014/03/ml-how-sigma-matters-in-svm-rbf-kernel.html) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
